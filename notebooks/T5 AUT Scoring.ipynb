{"cells":[{"cell_type":"markdown","metadata":{"id":"1siyOsKhXUBu"},"source":["# T5 Alternate Uses Task Scoring \n","\n","<a href=\"https://colab.research.google.com/github/massivetexts/llm_aut_study/blob/main/notebooks/T5 AUT Scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","\n","This notebook using PyTorch Lightning and HuggingFace Transformers to evaluate transformer architectures for originality scoring. Currently, it evaluates *T5*, though *BERT*, *distilBERT*, and *RoBERTa* may be sensible to measure.\n","\n","The ground truth was processed in [Process_AUT_GT.ipynb](https://colab.research.google.com/github/massivetexts/llm_aut_study/blob/main/notebook/Process_AUT_GT.ipynb). See also [GPT-3 AUT Scoring](https://colab.research.google.com/github/massivetexts/llm_aut_study/blob/main/notebooks/GPT-3%20AUT%20Scoring.ipynb).\n","\n","This is one of the experiments from Organisciak, P., Acar, S., Dumas, D., & Berthiaume, K. (2022). Beyond Semantic Distance: Automated Scoring of Divergent Thinking Greatly Improves with Large Language Models. http://dx.doi.org/10.13140/RG.2.2.32393.31840."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7033,"status":"ok","timestamp":1659739663502,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"IHYssUIWQ0fY","outputId":"b22cfd83-70bb-4687-f947-94362e5a3608"},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n","Torch version (check match to CUDA): 1.12.0+cu113\n"]}],"source":["#@title Installs\n","# for TPU support in PyTorch - this is probably dead in the water for performance reasons\n","#!pip install -q google-api-python-client==1.12.1 google-cloud-pubsub\n","tpu_or_gpu = \"gpu\" #@param [\"tpu\", \"gpu\"]\n","\n","if tpu_or_gpu == \"tpu\":\n","    !pip install -qq cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n","else:\n","    !nvcc --version\n","    import torch\n","    print(\"Torch version (check match to CUDA):\", torch.__version__) # doublecheck that torch cu version is same as actual cuda version\n","    # if there's a mismatch - best to find the torch that matches the install CUDA at\n","    # https://pytorch.org/get-started/previous-versions/\n","    #!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","!pip install -qq sentencepiece transformers pytorch-lightning wandb\n","#!pip install -q git+git://github.com/williamFalcon/pytorch-lightning.git@master --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659739663502,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"Radi6m5yoKuW","outputId":"37f05087-335f-4eeb-8d04-4be870becda3"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-c47bd875-bd49-e543-3ad9-2896f704f3d0)\n"]}],"source":["# GPU Memory: K80: 12GB, P100: 16GB, V100: 16GB, P4: 8GB, T4: 16GB, A100: 40GB\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"qSObRcjqRl8b"},"outputs":[],"source":["#@title Imports\n","import torch\n","import wandb\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers import WandbLogger\n","if tpu_or_gpu == 'tpu':\n","    import torch_xla\n","    import torch_xla.core.xla_model as xm\n","\n","import warnings\n","#import logging\n","import os\n","import pandas as pd\n","import glob\n","import json\n","import numpy as np\n","import random\n","import re\n","import argparse\n","from functools import lru_cache\n","from sklearn.model_selection import train_test_split\n","from datetime import datetime\n","\n","import shutil\n","\n","from tqdm import tqdm\n","from pathlib import Path\n","\n","from transformers import (AutoConfig, AutoModelForSeq2SeqLM, AutoTokenizer,\n","                          get_linear_schedule_with_warmup)\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import AdamW"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":7321,"status":"ok","timestamp":1659739681872,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"6dB2Rn1fXBIe","outputId":"1037430b-5008-4518-ea2d-042e9c29b073"},"outputs":[{"name":"stdout","output_type":"stream","text":["GT options ['gt_main', 'gt_bypart3', 'gt_byprompt4', 'gt_byparticipant', 'gt_byprompt', 'all', 'gt_main2', 'gt_main_std']\n","name t5-base-gt_byprompt-08-05-1659739678\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mporg\u001b[0m (\u001b[33mmassive-texts\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.13.1 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.13.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20220805_224800-xy8yij83</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/massive-texts/aut-t5/runs/xy8yij83\" target=\"_blank\">t5-base-gt_byprompt-08-05-1659739678</a></strong> to <a href=\"https://wandb.ai/massive-texts/aut-t5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#@title Params\n","base_dir = Path('drive/MyDrive/Grants/MOTES/') #@param { type: 'raw' }\n","gt_dir = base_dir / 'Data' / 'aut_ground_truth' #@param { type: 'raw' }\n","print(\"GT options\", [x.name.split('.')[0] for x in gt_dir.glob('*tar.gz')])\n","data_subdir = \"gt_byprompt\" #@param ['gt_main2', 'gt_byparticipant', 'gt_byprompt', 'all'] {allow-input: true}\n","\n","!cp \"{gt_dir}/{data_subdir}.tar.gz\" .\n","!rm -rf data\n","!tar -xf {data_subdir}.tar.gz\n","data_dir = Path(f\"data/{data_subdir}\")\n","\n","random_seed = 987 #@param {type:'number'}\n","#@markdown [mt5-base](https://huggingface.co/google/mt5-base) is the new multi-lingual extension.\n","#@markdown [t5-v.1.1](https://huggingface.co/google/t5-v1_1-base) is a slightly adjusted model, with no pretrained tasks.\n","model_name_or_path = \"t5-base\" #@param [\"t5-base\", \"t5-large\", \"google/t5-v1_1-large\", \"google/t5-v1_1-base\", \"google/mt5-base\"]\n","if '-large' in model_name_or_path:\n","    warnings.warn(\"Large models likely won't fine-tune on Colab GPUs. Half-precision or TPU training can support them in memory, though each currently stalls.\")\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","fname = f\"{model_name_or_path.split('/')[-1]}-{data_subdir}-{datetime.now().strftime('%m-%d-%s')}\"\n","\n","print('name', fname)\n","wandb_logger = WandbLogger(fname, project='aut-t5')\n","# manual login when something was crashing - it resolved itself\n","#with open('/content/drive/MyDrive/keys/wandbkey.txt', mode='r') as f:\n","#    wandb.login(key = f.read()) \n","set_seed(random_seed)"]},{"cell_type":"markdown","metadata":{"id":"_vDFnCQLYTpd"},"source":["## Model\n","\n","This model is a Pytorch Lightning model, adapted from [Patil Suraj's notebook](https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb) which in turn is based on the [Lightning docs](https://github.com/PytorchLightning/pytorch-lightning)."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"K34p4s0oYSjq"},"outputs":[],"source":["#@markdown *T5FineTuner* and Logger definitions\n","class T5FineTuner(pl.LightningModule):\n","    def __init__(self, model_name_or_path: str,\n","                tokenizer_name_or_path:str,\n","                data_dir:str,\n","                output_dir:str,\n","                max_seq_length: int=512,\n","                max_grad_norm: float = 1.0,\n","                gradient_accumulation_steps: int = 16,\n","                num_train_epochs: int = 2,\n","                learning_rate: float = 2e-5,\n","                adam_epsilon: float = 1e-8,\n","                warmup_steps: int = 0,\n","                early_stop_callback: bool = False, \n","                weight_decay: float = 0.0,\n","                batch_size: int = 4,\n","                pin_dl_memory: bool = False,\n","                data_loader_workers: int = 4, \n","                seed: float = 1234,\n","                **kwargs):\n","        super(T5FineTuner, self).__init__()\n","        self.save_hyperparameters()\n","\n","        self.config = AutoConfig.from_pretrained(self.hparams.model_name_or_path)\n","        self.model = AutoModelForSeq2SeqLM.from_pretrained(self.hparams.model_name_or_path,\n","                                                            config=self.config)\n","        self.tokenizer = AutoTokenizer.from_pretrained(self.hparams.model_name_or_path, model_max_length=512)\n","  \n","    def is_logger(self):\n","        return True\n","\n","  #def on_post_move_to_device(self):\n","      # This is an attempt to adjust for a TPU issue, but could be source of a \n","      # bug\n","  #  self.decoder.weight = self.encoder.weight\n","  \n","    #@torch.autocast(device_type=\"cuda\")\n","    def forward(\n","        self, input_ids, attention_mask=None, decoder_input_ids=None, \n","        decoder_attention_mask=None, labels=None\n","    ):\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=labels,\n","        )\n","\n","    def _step(self, batch):\n","        labels = batch[\"target_ids\"]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            labels=labels,\n","            decoder_attention_mask=batch['target_mask']\n","        )\n","\n","        loss = outputs[0]\n","\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","        self.log('train_loss', loss)\n","        return loss\n","\n","    def training_epoch_end(self, outputs):\n","        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n","        self.log(\"avg_train_loss\", avg_train_loss)\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","        self.log('val_loss', loss, on_epoch=True)\n","        return loss\n","\n","    @lru_cache()\n","    def total_steps(self):\n","        return len(self.train_dataloader()) // self.hparams.gradient_accumulation_steps * self.hparams.num_train_epochs\n","            \n","    def configure_optimizers(self):\n","        \"Prepare optimizer and schedule (linear warmup and decay)\"\n","\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.hparams.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        \n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                            lr=self.hparams.learning_rate, \n","                            eps=self.hparams.adam_epsilon)\n","        self.opt = optimizer\n","\n","        scheduler = get_linear_schedule_with_warmup(\n","                        self.opt,\n","                        num_warmup_steps=self.hparams.warmup_steps,\n","                        num_training_steps=self.total_steps()\n","        )\n","        self.lr_scheduler = scheduler\n","\n","        # Return a scheduler dict, as a second list with step interval so\n","        # that the warmup works properly\n","        # https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers\n","        return [self.opt], [{\"scheduler\": self.lr_scheduler, \"interval\": \"step\"}]\n","  \n","    def get_tqdm_dict(self):\n","        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","        return tqdm_dict\n","\n","    def train_dataloader(self):\n","        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", \n","                                    args=self.hparams)\n","        dataloader = DataLoader(train_dataset, batch_size=self.hparams.batch_size, \n","                                drop_last=True, shuffle=True,\n","                                pin_memory=self.hparams.pin_dl_memory,\n","                                num_workers=self.hparams.data_loader_workers)\n","\n","        return dataloader\n","\n","    def val_dataloader(self):\n","        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n","        return DataLoader(val_dataset, batch_size=self.hparams.batch_size,\n","                          pin_memory=self.hparams.pin_dl_memory,\n","                          num_workers=self.hparams.data_loader_workers)\n","\n","\n","#logger = logging.getLogger(__name__)\n","\n","#class LoggingCallback(pl.Callback):\n","#  def on_validation_end(self, trainer, pl_module):\n","#    logger.info(\"***** Validation results *****\")\n","#    if pl_module.is_logger():\n","#      metrics = trainer.callback_metrics\n","#      # Log results\n","#      for key in sorted(metrics):\n","#        if key not in [\"log\", \"progress_bar\"]:\n","#          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","#\n","#  def on_test_end(self, trainer, pl_module):\n","#    logger.info(\"***** Test results *****\")\n","#\n","#    if pl_module.is_logger():\n","#      metrics = trainer.callback_metrics\n","\n","      # Log and save results to file\n","#      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n","#      with open(output_test_results_file, \"w\") as writer:\n","#        for key in sorted(metrics):\n","#          if key not in [\"log\", \"progress_bar\"]:\n","#            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","#            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"]},{"cell_type":"markdown","metadata":{"id":"ZLLOlug1afkH"},"source":["## Set up Dataset\n","\n","T5 is text-to-text, so this class should simply format for that form of input."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"taoJzGgJae2O"},"outputs":[],"source":["#@markdown *AUTCorpus* definition\n","class AutCorpus():\n","    def __init__(self, tokenizer, data_dir, type_path=None, max_len=512):\n","        if type_path:\n","            self.path = os.path.join(data_dir, type_path)\n","        else:\n","            self.path = data_dir\n","        self.all_files = os.listdir(self.path)\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n","        self.ids = []\n","        \n","        self._build()\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, index):\n","        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n","        target_ids = self.targets[index][\"input_ids\"].squeeze()\n","\n","        src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","\n","        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n","\n","    def _build(self):\n","        for fname in self.all_files:\n","            with open(os.path.join(self.path, fname), 'r') as f:\n","                item = json.load(f)\n","            \n","            prefix = \"autscore\"\n","            \n","            if type(item['response']) is not str:\n","                item['response'] = '<unk>'\n","            try:\n","                prompt = \"question: \" + self._process_text(item['question'])\n","                response = \"response: \" + self._process_text(item['response'])\n","            except:\n","                # don't catch error - this may be something to investigate\n","                print(item, fname)\n","                raise\n","            in_text = f\"{prompt}\"\n","\n","            if 'target' in item:\n","                score = str(item['target'])\n","            else:\n","                # this data doesn't have ground truth\n","                score = '<unk>'\n","\n","            input = self.tokenizer(f\"{prefix} {prompt} {response}\",\n","                                   max_length=self.max_len,\n","                                   truncation=True,\n","                                   padding=\"max_length\",\n","                                   return_tensors=\"pt\")\n","            \n","            target = self.tokenizer(score,\n","                                    truncation=True,\n","                                    padding=\"max_length\",\n","                                    return_tensors=\"pt\")\n","            \n","            self.ids.append(item['id'])\n","            self.inputs.append(input)\n","            self.targets.append(target)\n","\n","\n","    def _process_text(self, line):\n","        line = line.strip()\n","        line = re.sub(\"[.;:!\\'?,\\\"()\\[\\]]\", \"\", line)\n","        return line + ' </s>'"]},{"cell_type":"markdown","metadata":{"id":"Yj15MS9TxOHf"},"source":["## Initialize T5 Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659739682203,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"xk2kCrL_ZxfN","outputId":"6a4fac41-8a02-4e28-8066-d46f323c4c07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checkpoints for this model+gt: [PosixPath('drive/MyDrive/Grants/MOTES/models/t5-base-gt_byprompt-08-05-1659715349.ckpt')] (Loading last)\n"]}],"source":["#@markdown checkpoint params\n","temp_checkpoint_dir = 'checkpoints' #@param {type:'string'}\n","final_checkpoint_dir = base_dir / 'models' #@param {type:'raw'}\n","load_checkpoint = True #@param {type:'boolean'}\n","if load_checkpoint:\n","    chkpts = sorted(list(final_checkpoint_dir.glob(f\"{model_name_or_path.split('/')[-1]}-{data_subdir}-*ckpt\")))\n","    print(\"Checkpoints for this model+gt:\", chkpts, \"(Loading last)\")\n","    checkpath = chkpts[-1]\n","\n","    if not os.path.exists(checkpath):\n","        print(\"checkpoint can't be found\")\n","        load_checkpoint = False"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"9aJ9jNQBxNsy"},"outputs":[],"source":["#@markdown ### Define train params and load model\n","epochs =  7#@param {type:\"integer\"}\n","\n","#@markdown #### Batch Sizes\n","batch_size =  5#@param {type:\"integer\"}\n","if (\"-large\" in model_name_or_path):\n","    try:\n","        assert (tpu_or_gpu == 'tpu')\n","    except:\n","        warnings.warn(\"Large models likely need TPU.\")\n","\n","#@markdown `power` and `binsearch` scaling will start with a batch size of 1 and keep doubling until it reaches OOM\n","auto_scale_batch_size = None #@param [\"None\", \"\\\"power\\\"\", \"\\\"binsearch\\\"\"] {type:\"raw\"}\n","#@markdown From [PyLightning training tips](https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html): \n","#@markdown accumulating gradients helps improve training by effectively\n","#@markdown mimicing a bigger batchsize (16 is a good value)\n","gradient_accumulation_steps = 16 #@param {type:\"integer\"}\n","\n","args = dict(\n","    data_dir=data_dir, # path for data files\n","    output_dir=temp_checkpoint_dir, # path to save the checkpoints\n","    model_name_or_path=model_name_or_path,\n","    tokenizer_name_or_path=model_name_or_path,\n","    max_seq_length=512,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    learning_rate=3e-4,\n","    weight_decay=0.0,\n","    adam_epsilon=1e-8,\n","    warmup_steps=20,\n","    batch_size=batch_size,\n","    num_train_epochs=epochs,\n","    # rule of thumb for data loader num_workers is 4 * num_GPU, unless memory is at a premium\n","    # https://www.pytorchlightning.ai/blog/7-tips-to-maximize-pytorch-performance\n","    data_loader_workers=4,\n","    max_grad_norm=1, # clip to avoid exploding gradients; 0 is off, 0.5 is sensible https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html#gradient-clipping\n","    seed=random_seed,\n",")\n","\n","\n","pin_dl_memory = True #@param {type:'boolean'}\n","args['pin_dl_memory'] = pin_dl_memory\n","#@markdown Use 16-bit precision. This can be done without apex in newer pytorch\n","fp_16 = False #@param {type:'boolean'}\n","args['fp_16'] = fp_16\n","\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    dirpath=args['output_dir'],\n","    filename=data_subdir+'-{epoch}-{val_loss:.2f}-{other_metric:.2f}',\n","    monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",")\n","\n","if load_checkpoint:\n","    model = T5FineTuner.load_from_checkpoint(checkpath)\n","else:\n","    model = T5FineTuner(**args)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12208,"status":"ok","timestamp":1659739715762,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"mgPuul0mqY7J","outputId":"ce7a95f9-7120-49bc-ed36-2d6c2077d1ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["autscore question: What is a surprising use for a FORK response: as a homemade slingshot\n","3.5\n"]}],"source":["corpus = AutCorpus(model.tokenizer, data_dir, \"train\")\n","print(model.tokenizer.decode(corpus[10]['source_ids'], skip_special_tokens=True))\n","print(model.tokenizer.decode(corpus[10]['target_ids'], skip_special_tokens=True))"]},{"cell_type":"markdown","metadata":{"id":"P9D8PiWIMNXl"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1659715373708,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"7KmW9DeJzFOb","outputId":"b90e0580-9fc5-4e60-b41d-edcf638a4df5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n","  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]}],"source":["#@markdown Initialize Trainer\n","def get_dataset(tokenizer, type_path, args):\n","    # This is a generic function called in the Lightning module. \n","    # return the training/validation dataset\n","    return AutCorpus(tokenizer=tokenizer, data_dir=args.data_dir, \n","                          type_path=type_path,  max_len=args.max_seq_length)\n","\n","#Initialize trainer\n","train_params = dict(\n","    accumulate_grad_batches=gradient_accumulation_steps,\n","    max_epochs=args['num_train_epochs'],\n","    precision= 16 if args['fp_16'] else 32,\n","    amp_backend='native',\n","    auto_scale_batch_size=auto_scale_batch_size,\n","    gradient_clip_val=args['max_grad_norm'],\n","    logger = wandb_logger,\n","    callbacks=[#LoggingCallback(),\n","               ],\n",")\n","if 'byprompt' not in data_subdir:\n","    train_params['callbacks'] += [pl.callbacks.EarlyStopping(monitor=\"val_loss\"),\n","                                  checkpoint_callback]\n","\n","tpu_cores = 1#@param {type:'integer'}\n","if tpu_or_gpu == \"tpu\":\n","    train_params['tpu_cores'] = tpu_cores \n","elif tpu_or_gpu == \"gpu\":\n","    train_params['gpus'] = 1\n","else:\n","    raise\n","\n","trainer = pl.Trainer(**train_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["e476784c3e5b464eb3a1468137b58c76","2881fafbb32f4f0aba00630eaa8e9a8c","1af5b2c9ab4145d5aaac908d85ee24f8","63daefd784114e75b52538cb73b522c9","a4699a1091b04c2bbba43f0d77a6b8cd","702934a1cbab4fe099e2c52e634e2fec","1a1ea8f0e853455c91350c208e6d5922","13d44876a821472caed39e46da089a65","c2b5292c01c346b4b1a9722990358a02","a4f76fcb279d4deb9036396da4fa03f7","fe732d1e76924fedb28ff031a531bf33","69798b65512e43888e724ce37572f5f8","bc0994f339c04cb1acd3ff26f10ef9c0","33e17ae8c9fa49af88d83f8de4662412","fb22a594e65c4a0cb75552111eefe16b","a0f35311ad874998952b83cd714f2822","9e3714bd217d40dc93d189a8431c09b3","bf769976ad7b4a859cc0e6b71f811089","fbb4d00dc35244cba57f83686d492e74","8bd1c22584a44a1f91c1d8e05b549683","796905c56476482dad7a28ce7bde7d64","af7c29d75aea4c44a41279d6857fa27f"]},"executionInfo":{"elapsed":116577,"status":"ok","timestamp":1659738551231,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"hyT8pWXEMdo8","outputId":"3e2db338-6cb3-4f12-de38-6b8f43704cd9"},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                       | Params\n","-----------------------------------------------------\n","0 | model | T5ForConditionalGeneration | 222 M \n","-----------------------------------------------------\n","222 M     Trainable params\n","0         Non-trainable params\n","222 M     Total params\n","891.614   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e476784c3e5b464eb3a1468137b58c76","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/data.py:142: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n","  f\"Total length of `{dataloader.__class__.__name__}` across ranks is zero.\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69798b65512e43888e724ce37572f5f8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:657: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["trainer.fit(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xB7VsM2RESBg"},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tJawr4Rxlkk"},"outputs":[],"source":["# save checkpoint and logs\n","trainer.save_checkpoint(final_checkpoint_dir / (fname + '.ckpt'))\n","\n","#logpath = Path('lightning_logs')\n","#last_version = max([int(x.name.split('version_')[1]) for x in logpath.glob(\"*version*\")])\n","#last_logs = logpath / f\"version_{last_version}\"\n","#shutil.move(last_logs, base_dir / \"Data/logs\" / fname)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EClJ4qnCIqOi"},"outputs":[],"source":["1"]},{"cell_type":"markdown","metadata":{"id":"xAAM5VNVSwtO"},"source":["## Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"elapsed":1396,"status":"ok","timestamp":1659739717153,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"SBCQDVc0KWeg","outputId":"9890ea0f-8379-4c90-a106-245f89d61a46"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1207: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  UserWarning,\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.8'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["ex = \"autscore question: What is a suprising use for an hammer  response: art\"\n","inputs = model.tokenizer(ex, return_tensors=\"pt\",\n","                         truncation=True, padding=\"max_length\")\n","generation_output = model.model.generate(**inputs)\n","model.tokenizer.decode(generation_output[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jahIkLJMSqMs","outputId":"2f90e04e-a723-4dcd-e3fd-0ee415a44dba"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/14 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 1/14 [04:51<1:03:09, 291.51s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 2/14 [09:37<57:42, 288.50s/it]  "]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 21%|██▏       | 3/14 [14:21<52:29, 286.29s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▊       | 4/14 [19:05<47:32, 285.21s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 5/14 [23:47<42:37, 284.18s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 6/14 [28:33<37:59, 284.93s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 7/14 [33:20<33:18, 285.55s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 8/14 [38:05<28:31, 285.28s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 9/14 [42:45<23:37, 283.56s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████▏  | 10/14 [47:21<18:44, 281.19s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▊  | 11/14 [51:59<14:00, 280.26s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 12/14 [56:41<09:21, 280.78s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 13/14 [1:01:21<04:40, 280.77s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14/14 [1:02:30<00:00, 267.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Done\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["testdata = AutCorpus(model.tokenizer, data_dir, 'test')\n","loader = DataLoader(testdata,batch_size=256, shuffle=False, num_workers=4)\n","\n","dec = []\n","texts = []\n","targets = []\n","for batch in tqdm(loader):\n","    print('.', end='')\n","    outs = model.model.generate(input_ids=batch['source_ids'], \n","                              attention_mask=batch['source_mask'] ,\n","                              max_length=512)\n","    \n","    dec += [model.tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n","\n","    texts += [model.tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['source_ids']]\n","    targets += [model.tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]\n","\n","print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NpZuMLSyGxbL","outputId":"7306aca2-9d47-4330-c40a-d04a7773f777"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-8cc862a1a147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'participant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prompt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'Data'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'evaluation'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdata_subdir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3482\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3483\u001b[0m         )\n\u001b[1;32m   3484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         ) as handles:\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Grants/MOTES/Data/evaluation/gt_byprompt/t5-base-gt_byprompt-08-05-1659739678.csv'"]}],"source":["# load test data at dataframe, convert outputdata to dataframe, merge and save results\n","testdata_df = pd.DataFrame([pd.read_json(x, orient='index')[0] for x in (data_dir / 'test').glob('*json')])\n","\n","outdata = pd.DataFrame(zip(testdata.ids, texts, targets, dec), columns=['id', 'prompt', 'target', 'predicted_raw'])\n","outdata['predicted'] = pd.to_numeric(outdata.predicted_raw, errors='coerce')\n","outdata.target = pd.to_numeric(outdata.target, errors='coerce')\n","outdata = outdata.rename(columns={'prompt':'t5-input'})\n","outdata['model'] = 't5-base'\n","outdata['split'] = data_subdir\n","x = outdata.drop('target', axis='columns').merge(testdata_df, how='left')\n","assert len(x) == len(outdata)\n","x = x[['id', 'model', 'participant', 'prompt', 'target', 'predicted', 'src', 'split']]\n","x.to_csv(base_dir / 'Data' / 'evaluation' / data_subdir / (fname + '.csv'))\n","\n","outdata.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gOD7MXwnCb2j"},"outputs":[],"source":["x.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vyBRwIvF8eAK","outputId":"30837aa3-fc44-456d-b672-dccab524a735"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-57e40169-09fb-43c0-83f7-6b3bfa899e64\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>target</th>\n","      <th>predicted</th>\n","    </tr>\n","    <tr>\n","      <th>src</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">hmsl</th>\n","      <th>target</th>\n","      <td>1.000000</td>\n","      <td>0.703223</td>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <td>0.703223</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">motes</th>\n","      <th>target</th>\n","      <td>1.000000</td>\n","      <td>0.320681</td>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <td>0.320681</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">paca</th>\n","      <th>target</th>\n","      <td>1.000000</td>\n","      <td>0.773263</td>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <td>0.773263</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"2\" valign=\"top\">s08</th>\n","      <th>target</th>\n","      <td>1.000000</td>\n","      <td>0.498952</td>\n","    </tr>\n","    <tr>\n","      <th>predicted</th>\n","      <td>0.498952</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57e40169-09fb-43c0-83f7-6b3bfa899e64')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-57e40169-09fb-43c0-83f7-6b3bfa899e64 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-57e40169-09fb-43c0-83f7-6b3bfa899e64');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                   target  predicted\n","src                                 \n","hmsl  target     1.000000   0.703223\n","      predicted  0.703223   1.000000\n","motes target     1.000000   0.320681\n","      predicted  0.320681   1.000000\n","paca  target     1.000000   0.773263\n","      predicted  0.773263   1.000000\n","s08   target     1.000000   0.498952\n","      predicted  0.498952   1.000000"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["x.groupby('src').corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1651261614429,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"xZAMnE2PEWeI","outputId":"7fee6f8c-c17c-4b57-c0c8-b24063bf72b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Game 1\n","\tT5:\t 0.34 \tExamples: 90\n","Game 2\n","\tT5:\t 0.51 \tExamples: 72\n","Game 3\n","\tT5:\t 0.35 \tExamples: 45\n","Game 4\n","\tT5:\t 0.41 \tExamples: 54\n","PACA\n","\tT5:\t 0.68 \tExamples: 665\n","MOTES\n","\tT5:\t 0.43 \tExamples: 261\n"]}],"source":["for i in range(1, 5):\n","    subset = outdata[outdata.id.str.contains(f'-g{i}')]\n","    c = subset.corr().round(2)\n","    print(f\"Game {i}\")\n","    print(\"\\tT5:\\t\", c.loc['predicted', 'target'], '\\tExamples:', len(subset))\n","\n","for src in ['paca', 'motes']:\n","    subset = outdata[outdata.id.str.contains(f'{src}-')]\n","    c = subset.corr().round(2)\n","    print(src.upper())\n","    print(\"\\tT5:\\t\", c.loc['predicted', 'target'], '\\tExamples:', len(subset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xM5s4CG7TNJu"},"outputs":[],"source":["import difflib\n","import time\n","d = difflib.Differ()\n","with open(time.strftime(\"spelling-corrections-%m-%d-%Y.txt\"), mode='w') as f:\n","    for i in range(len(texts)):\n","        #print(\"Input\\t\\t\", texts[i])\n","        #print(\"Hand Fixed\\t\", targets[i])\n","        #print(\"Auto fixed\\t\", dec[i])\n","        diffs = [\"\\t\\t\\t\"+x for x in d.compare([texts[i]+'\\n'], [targets[i]+'\\n'])]\n","        diffs[0] = \"Original:\" + diffs[0][2:]\n","        if len(diffs) > 1:\n","            j = 2 if diffs[1].startswith('\\t\\t\\t?') else 1\n","            diffs = [diffs[0]] + diffs[j:]\n","            diffs[1] = \"Hand-fixed:\" + diffs[1][2:]\n","        else:\n","            diffs.append(\"(Hand-fix is unchanged)\\n\")\n","        diffs_auto = [\"\\t\\t\\t\"+x for x in d.compare([texts[i]+'\\n'], [dec[i]+'\\n'])]\n","        if len(diffs_auto) > 2:\n","            j = 2 if diffs_auto[1].startswith('\\t\\t\\t?') else 1\n","            diffs_auto[j] = \"Auto-fixed:\" + diffs_auto[j][2:]\n","            diffs += diffs_auto[j:]\n","\n","        else:\n","            diffs.append(\"(Auto-fix is unchanged)\\n\")\n","\n","        diffs.append(\"=================\\n\")\n","        \n","        if len(diffs) > 4:\n","            print(\"\".join([x.replace(':\\t', ':\\t\\t') for x in diffs]))\n","            f.write(\"\".join(diffs))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DY1yzbuUSNph"},"outputs":[],"source":["## Compare to Glove"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTe8H7i0JFth"},"outputs":[],"source":["glove = pd.read_csv('glove_test_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":759},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1632344653879,"user":{"displayName":"Peter Organisciak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GghoA5C3Ltlx3IMorP8yXv5Y0sdDqch_WyyKbePqJc=s64","userId":"18310606572067872626"},"user_tz":360},"id":"B3q0yNG8SWu3","outputId":"8230ad72-a681-43d9-ce51-0d17610debc8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt_x</th>\n","      <th>question</th>\n","      <th>response</th>\n","      <th>truth</th>\n","      <th>glove_norm</th>\n","      <th>t5</th>\n","      <th>prompt_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>motes-14ML-g4_library</td>\n","      <td>library</td>\n","      <td>When the kids were in the library they found...</td>\n","      <td>a funny book and laugh but their voices where ...</td>\n","      <td>5.0</td>\n","      <td>4.5</td>\n","      <td>5.5</td>\n","      <td>autscore question: When the kids were in the l...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>paca-shoe-88852d0f1a994dae025ac0605ed08786</td>\n","      <td>shoe</td>\n","      <td>What is a suprising use for a SHOE?</td>\n","      <td>hold a door open</td>\n","      <td>3.5</td>\n","      <td>5.0</td>\n","      <td>3.5</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>paca-pants-e6a9d88312672fa11002a5c69c111eb0</td>\n","      <td>pants</td>\n","      <td>What is a suprising use for a PANTS?</td>\n","      <td>keep someone warm</td>\n","      <td>1.5</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>motes-1RG-g1_backpack</td>\n","      <td>backpack</td>\n","      <td>What is a surprising use for a BACKPACK?</td>\n","      <td>A halloween costume.</td>\n","      <td>4.5</td>\n","      <td>5.0</td>\n","      <td>4.5</td>\n","      <td>autscore question: What is a surprising use fo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>paca-rope-9f37391faf541c2e2a2a7dea1d470a97</td>\n","      <td>rope</td>\n","      <td>What is a suprising use for a ROPE?</td>\n","      <td>use it to secure a boat</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>741</th>\n","      <td>paca-fork-8b38ed63b9c167401ba2a354f67016fd</td>\n","      <td>fork</td>\n","      <td>What is a suprising use for a FORK?</td>\n","      <td>eating utensil</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>paca-brick-f09328d495fa622700aabe5707edf00b</td>\n","      <td>brick</td>\n","      <td>What is a suprising use for a BRICK?</td>\n","      <td>hit</td>\n","      <td>4.0</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>paca-fork-68de719c46275bf4cad9fbfe8c088cd3</td>\n","      <td>fork</td>\n","      <td>What is a suprising use for a FORK?</td>\n","      <td>to put holes in wall</td>\n","      <td>3.5</td>\n","      <td>4.5</td>\n","      <td>3.5</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>744</th>\n","      <td>paca-brick-976ce911df1da1cf7090aff8608f50b0</td>\n","      <td>brick</td>\n","      <td>What is a suprising use for a BRICK?</td>\n","      <td>making house</td>\n","      <td>1.5</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","    <tr>\n","      <th>745</th>\n","      <td>paca-book-a6ba7998e42b8b3174317ea6e167f331</td>\n","      <td>book</td>\n","      <td>What is a suprising use for a BOOK?</td>\n","      <td>donate it</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>3.5</td>\n","      <td>autscore question: What is a suprising use for...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>746 rows × 8 columns</p>\n","</div>"],"text/plain":["                                              id  ...                                           prompt_y\n","0                          motes-14ML-g4_library  ...  autscore question: When the kids were in the l...\n","1     paca-shoe-88852d0f1a994dae025ac0605ed08786  ...  autscore question: What is a suprising use for...\n","2    paca-pants-e6a9d88312672fa11002a5c69c111eb0  ...  autscore question: What is a suprising use for...\n","3                          motes-1RG-g1_backpack  ...  autscore question: What is a surprising use fo...\n","4     paca-rope-9f37391faf541c2e2a2a7dea1d470a97  ...  autscore question: What is a suprising use for...\n","..                                           ...  ...                                                ...\n","741   paca-fork-8b38ed63b9c167401ba2a354f67016fd  ...  autscore question: What is a suprising use for...\n","742  paca-brick-f09328d495fa622700aabe5707edf00b  ...  autscore question: What is a suprising use for...\n","743   paca-fork-68de719c46275bf4cad9fbfe8c088cd3  ...  autscore question: What is a suprising use for...\n","744  paca-brick-976ce911df1da1cf7090aff8608f50b0  ...  autscore question: What is a suprising use for...\n","745   paca-book-a6ba7998e42b8b3174317ea6e167f331  ...  autscore question: What is a suprising use for...\n","\n","[746 rows x 8 columns]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["a = glove[['id','prompt','question','response', 'truth', 'glove_norm']]\n","b = a.merge(outdata[['id', 't5', 'prompt']], how='inner', on='id')\n","b.to_csv('t5-and-glove.csv')\n","b"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123,"status":"ok","timestamp":1632345561522,"user":{"displayName":"Peter Organisciak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GghoA5C3Ltlx3IMorP8yXv5Y0sdDqch_WyyKbePqJc=s64","userId":"18310606572067872626"},"user_tz":360},"id":"SRHLvSsdW0l-","outputId":"0813fe71-60ac-4253-b97c-4d8fb4cc2724"},"outputs":[{"name":"stdout","output_type":"stream","text":["Game 1\n","\tGlove:\t 0.22\n","\tT5:\t 0.47\n","Game 2\n","\tGlove:\t 0.47\n","\tT5:\t 0.37\n","Game 3\n","\tGlove:\t 0.51\n","\tT5:\t 0.31\n","Game 4\n","\tGlove:\t 0.43\n","\tT5:\t 0.41\n"]}],"source":["for i in range(1, 5):\n","    c = b[b.id.str.contains(f'-g{i}')].corr().round(2)\n","    print(f\"Game {i}\")\n","    print(\"\\tGlove:\\t\", c.loc['glove_norm', 'truth'])\n","    print(\"\\tT5:\\t\", c.loc['t5', 'truth'])"]},{"cell_type":"markdown","metadata":{"id":"zpiRjE0EE-qT"},"source":["T5 \n","\n","```\n","Game 1\n","\tGlove:\t0.22\n","\tT5 1:\t 0.47\n","    T5 2:\t 0.39\n","\n","Game 2\n","\tGlove:\t0.47\n","\tT5 1:\t 0.37\n","    T5 2:\t 0.46\n","\n","Game 3 (removed post-pilot)\n","\tGlove:\t0.51\n","\tT5 1:\t 0.31\n","    T5 2:\t 0.48\n","\n","Game 4 (game 3 post-pilot)\n","\tGlove:\t0.43\n","\tT5 1:\t 0.41\n","    T5 2:\t 0.24\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":556,"status":"ok","timestamp":1649788955712,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"RgPmzee1SXR9","outputId":"b9b8d7f5-3579-4fe2-a1ef-1961a9393ab8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-23bb37e9-5253-46d4-b6a8-be6de66e87b6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>truth</th>\n","      <th>t5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>truth</th>\n","      <td>1.000000</td>\n","      <td>0.661971</td>\n","    </tr>\n","    <tr>\n","      <th>t5</th>\n","      <td>0.661971</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23bb37e9-5253-46d4-b6a8-be6de66e87b6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-23bb37e9-5253-46d4-b6a8-be6de66e87b6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-23bb37e9-5253-46d4-b6a8-be6de66e87b6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["          truth        t5\n","truth  1.000000  0.661971\n","t5     0.661971  1.000000"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["outdata.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAXXeVbTS2qh"},"outputs":[],"source":["b.to_csv('t5-and-glove.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1632344924935,"user":{"displayName":"Peter Organisciak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GghoA5C3Ltlx3IMorP8yXv5Y0sdDqch_WyyKbePqJc=s64","userId":"18310606572067872626"},"user_tz":360},"id":"WkrDaPPqVswT","outputId":"605565b9-68a7-4a88-d78a-8f7443ac5584"},"outputs":[{"data":{"text/plain":["(746, 8)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["b.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1632344703119,"user":{"displayName":"Peter Organisciak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GghoA5C3Ltlx3IMorP8yXv5Y0sdDqch_WyyKbePqJc=s64","userId":"18310606572067872626"},"user_tz":360},"id":"U7jp7sf1TQ4z","outputId":"4073a2c1-dae1-473b-f557-d4c573236b6a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>truth</th>\n","      <th>t5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>truth</th>\n","      <td>1.000000</td>\n","      <td>0.690679</td>\n","    </tr>\n","    <tr>\n","      <th>t5</th>\n","      <td>0.690679</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          truth        t5\n","truth  1.000000  0.690679\n","t5     0.690679  1.000000"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["outdata.corr()"]},{"cell_type":"markdown","metadata":{"id":"PRoOo4NO908_"},"source":["## Run on Full MOTES Data\n","\n","Data was pre-processed in [Prepare Motes Full Data.ipynb](https://colab.research.google.com/drive/17pUEqMHbhx8mnDg9EHiqeJ3QMc7QtMMO?usp=sharing)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2317408,"status":"ok","timestamp":1652298366553,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"NE58IRiutjg7","outputId":"62e20008-1449-425e-f737-92a28714f890"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/50 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 1/50 [01:54<1:33:47, 114.84s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 2/50 [03:47<1:30:48, 113.51s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 3/50 [05:39<1:28:33, 113.06s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 4/50 [07:31<1:26:22, 112.66s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 5/50 [09:24<1:24:25, 112.57s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 6/50 [11:16<1:22:32, 112.56s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 7/50 [13:08<1:20:31, 112.35s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 8/50 [15:01<1:18:42, 112.44s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 9/50 [16:53<1:16:47, 112.39s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 10/50 [18:45<1:14:51, 112.29s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 11/50 [20:38<1:12:59, 112.31s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 12/50 [22:30<1:11:10, 112.37s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 13/50 [24:22<1:09:09, 112.16s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 14/50 [26:14<1:07:13, 112.04s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 15/50 [28:05<1:05:16, 111.89s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 16/50 [29:57<1:03:20, 111.77s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 17/50 [31:49<1:01:29, 111.79s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 18/50 [33:40<59:31, 111.61s/it]  "]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 19/50 [35:31<57:38, 111.58s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 20/50 [37:23<55:48, 111.63s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 21/50 [39:15<54:00, 111.73s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 22/50 [41:06<52:06, 111.68s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 23/50 [42:58<50:15, 111.70s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 24/50 [44:50<48:28, 111.87s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 25/50 [46:43<46:41, 112.05s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 26/50 [48:35<44:47, 111.96s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 27/50 [50:26<42:53, 111.87s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 28/50 [52:18<41:00, 111.85s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 29/50 [54:10<39:10, 111.92s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 30/50 [56:02<37:18, 111.93s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 31/50 [57:55<35:29, 112.09s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 32/50 [59:47<33:39, 112.19s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 33/50 [1:01:40<31:48, 112.29s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 34/50 [1:03:32<29:57, 112.34s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 35/50 [1:05:24<28:04, 112.30s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 36/50 [1:07:16<26:11, 112.27s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 37/50 [1:09:09<24:19, 112.26s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 38/50 [1:11:02<22:29, 112.49s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 39/50 [1:12:54<20:37, 112.54s/it]"]},{"name":"stdout","output_type":"stream","text":[".."]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 41/50 [1:16:39<16:51, 112.41s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 42/50 [1:18:32<14:59, 112.47s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 43/50 [1:20:25<13:08, 112.58s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 44/50 [1:22:20<11:21, 113.51s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 45/50 [1:24:13<09:26, 113.35s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 46/50 [1:26:05<07:32, 113.00s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 47/50 [1:27:58<05:38, 112.92s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 48/50 [1:29:51<03:45, 112.80s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 49/50 [1:31:43<01:52, 112.83s/it]"]},{"name":"stdout","output_type":"stream","text":["."]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 50/50 [1:32:20<00:00, 110.82s/it]"]},{"name":"stdout","output_type":"stream","text":["Done\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["fulldata = AutCorpus(model.tokenizer, base_dir/\"Data/motes-full/json\", None)\n","loader = DataLoader(fulldata,batch_size=128, shuffle=False, num_workers=4)\n","\n","dec = []\n","texts = []\n","targets = []\n","for batch in tqdm(loader):\n","    print('.', end='')\n","    outs = model.model.generate(input_ids=batch['source_ids'], \n","                              attention_mask=batch['source_mask'] ,\n","                              max_length=512)\n","    \n","    dec += [model.tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n","\n","    texts += [model.tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['source_ids']]\n","    targets += [model.tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['target_ids']]\n","\n","print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1652298367149,"user":{"displayName":"Peter Organisciak","userId":"18310606572067872626"},"user_tz":360},"id":"ltRdvsMR1s1n","outputId":"e9e929c1-a28f-4968-f998-d34c48a9135a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b04e2bc8-26d0-4b72-aff1-e00a556289fc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>target</th>\n","      <th>predicted_raw</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2007</th>\n","      <td>motesfull-R_3Mu0oACM7BbSLFa-g2_wet</td>\n","      <td>autscore question: What is a surprising exampl...</td>\n","      <td>NaN</td>\n","      <td>6.5</td>\n","      <td>6.5</td>\n","    </tr>\n","    <tr>\n","      <th>2945</th>\n","      <td>motesfull-R_Z33wMWuM1dL68gh-g3_schoolbus</td>\n","      <td>autscore question: When I got on the school bu...</td>\n","      <td>NaN</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","    </tr>\n","    <tr>\n","      <th>1431</th>\n","      <td>motesfull-R_1lawf8FaYk3WmPt-g3_library</td>\n","      <td>autscore question: When the kids were in the l...</td>\n","      <td>NaN</td>\n","      <td>5.5</td>\n","      <td>5.5</td>\n","    </tr>\n","    <tr>\n","      <th>3345</th>\n","      <td>motesfull-R_1NrHH6CSGCHDezr-g2_red</td>\n","      <td>autscore question: What is a surprising exampl...</td>\n","      <td>NaN</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","    </tr>\n","    <tr>\n","      <th>5558</th>\n","      <td>motesfull-R_3QPCr3zlr9JKxe1-g1_spoon</td>\n","      <td>autscore question: What is a surprising use fo...</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b04e2bc8-26d0-4b72-aff1-e00a556289fc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b04e2bc8-26d0-4b72-aff1-e00a556289fc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b04e2bc8-26d0-4b72-aff1-e00a556289fc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                            id  \\\n","2007        motesfull-R_3Mu0oACM7BbSLFa-g2_wet   \n","2945  motesfull-R_Z33wMWuM1dL68gh-g3_schoolbus   \n","1431    motesfull-R_1lawf8FaYk3WmPt-g3_library   \n","3345        motesfull-R_1NrHH6CSGCHDezr-g2_red   \n","5558      motesfull-R_3QPCr3zlr9JKxe1-g1_spoon   \n","\n","                                                 prompt  target predicted_raw  \\\n","2007  autscore question: What is a surprising exampl...     NaN           6.5   \n","2945  autscore question: When I got on the school bu...     NaN           4.5   \n","1431  autscore question: When the kids were in the l...     NaN           5.5   \n","3345  autscore question: What is a surprising exampl...     NaN           3.5   \n","5558  autscore question: What is a surprising use fo...     NaN           1.0   \n","\n","      predicted  \n","2007        6.5  \n","2945        4.5  \n","1431        5.5  \n","3345        3.5  \n","5558        1.0  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["outdata = pd.DataFrame(zip(fulldata.ids, texts, targets, dec), columns=['id', 'prompt', 'target', 'predicted_raw'])\n","outdata['predicted'] = pd.to_numeric(outdata.predicted_raw, errors='coerce')\n","outdata.target = pd.to_numeric(outdata.target, errors='coerce')\n","outdata.to_csv(base_dir / 'Data' / 'evaluation' / ('motesfull-' + fname + '.csv'))\n","outdata.sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZW-T_mUSaHJ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[{"file_id":"12dTHThcO1p4Er8oLZ6WWqmM8D828Q7w_","timestamp":1630600453171}]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"e93f6973baf80d840d9d6715f091ca11c0bba5902c2f522aa0ee562f8ebeaf67"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"13d44876a821472caed39e46da089a65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a1ea8f0e853455c91350c208e6d5922":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1af5b2c9ab4145d5aaac908d85ee24f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_13d44876a821472caed39e46da089a65","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2b5292c01c346b4b1a9722990358a02","value":0}},"2881fafbb32f4f0aba00630eaa8e9a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_702934a1cbab4fe099e2c52e634e2fec","placeholder":"​","style":"IPY_MODEL_1a1ea8f0e853455c91350c208e6d5922","value":"Sanity Checking: "}},"33e17ae8c9fa49af88d83f8de4662412":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbb4d00dc35244cba57f83686d492e74","max":3337,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bd1c22584a44a1f91c1d8e05b549683","value":1520}},"63daefd784114e75b52538cb73b522c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4f76fcb279d4deb9036396da4fa03f7","placeholder":"​","style":"IPY_MODEL_fe732d1e76924fedb28ff031a531bf33","value":" 0/? [00:00&lt;?, ?it/s]"}},"69798b65512e43888e724ce37572f5f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc0994f339c04cb1acd3ff26f10ef9c0","IPY_MODEL_33e17ae8c9fa49af88d83f8de4662412","IPY_MODEL_fb22a594e65c4a0cb75552111eefe16b"],"layout":"IPY_MODEL_a0f35311ad874998952b83cd714f2822"}},"702934a1cbab4fe099e2c52e634e2fec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796905c56476482dad7a28ce7bde7d64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bd1c22584a44a1f91c1d8e05b549683":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e3714bd217d40dc93d189a8431c09b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0f35311ad874998952b83cd714f2822":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a4699a1091b04c2bbba43f0d77a6b8cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"a4f76fcb279d4deb9036396da4fa03f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af7c29d75aea4c44a41279d6857fa27f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc0994f339c04cb1acd3ff26f10ef9c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e3714bd217d40dc93d189a8431c09b3","placeholder":"​","style":"IPY_MODEL_bf769976ad7b4a859cc0e6b71f811089","value":"Epoch 8:  46%"}},"bf769976ad7b4a859cc0e6b71f811089":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2b5292c01c346b4b1a9722990358a02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e476784c3e5b464eb3a1468137b58c76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2881fafbb32f4f0aba00630eaa8e9a8c","IPY_MODEL_1af5b2c9ab4145d5aaac908d85ee24f8","IPY_MODEL_63daefd784114e75b52538cb73b522c9"],"layout":"IPY_MODEL_a4699a1091b04c2bbba43f0d77a6b8cd"}},"fb22a594e65c4a0cb75552111eefe16b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_796905c56476482dad7a28ce7bde7d64","placeholder":"​","style":"IPY_MODEL_af7c29d75aea4c44a41279d6857fa27f","value":" 1520/3337 [20:35&lt;24:36,  1.23it/s, loss=0.507, v_num=a78e]"}},"fbb4d00dc35244cba57f83686d492e74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe732d1e76924fedb28ff031a531bf33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}